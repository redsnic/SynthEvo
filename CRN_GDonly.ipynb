{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finiding quasi-adaptive CRN with gradient-guided evolution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init vars\n"
     ]
    }
   ],
   "source": [
    "eval(Meta.parse(\"@variables \" * join([ifelse(i==3 && j==80, \"\", \"ks_\" * string(i) * \"_\" * string(j) *\"(t), \") for i in 1:3 for j in 1:80]) * \"ks_\" * string(3) * \"_\" * string(80) * \"(t)\"))\n",
    "println(\"init vars\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem's setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load libraries\n",
    "include(\"CRNExplore.jl\")\n",
    "include(\"SymbolicOps.jl\")\n",
    "\n",
    "# fixed, basic steps\n",
    "\n",
    "target = N\n",
    "crn = create_reactions(N)\n",
    "ode_crn = convert(ODESystem, crn)\n",
    "np = count_parameters(N)\n",
    "\n",
    "# set up hyperparameters\n",
    "\n",
    "t0 = 10.\n",
    "t1 = 20.\n",
    "input = 1.\n",
    "perturbation = 1.\n",
    "\n",
    "# generate p0\n",
    "pars_v = [rand() for i in 1:np]\n",
    "pars_l = assemble_opt_parameters_and_varables(pars_v, N)\n",
    "\n",
    "# set up the loss function\n",
    "weights = [10., 10., 8.0/80, 10.] #[1.0/50, 1.0, 1.0/80, 1.0] #[1., 0.01, 0.01, 1.] # this descends smoothly\n",
    "p=0.1\n",
    "d=0.5\n",
    "f_ss=0.5\n",
    "\n",
    "# finalize initialization\n",
    "\n",
    "ext_ode = make_sensitivity_ode(ode_crn, pars_l.p)\n",
    "\n",
    "norm_for_sensitivity_loss = 1\n",
    "norm_for_ss_loss = 1\n",
    "norm_for_adaptation_loss = 1\n",
    "loss_args = prepare_args(nothing, target, t0, t1, pars_l, weights, p, d, f_ss, norm_for_sensitivity_loss, norm_for_ss_loss, norm_for_adaptation_loss)\n",
    "s_loss = total_loss_symbolic(loss_args)\n",
    "loss_derivatives = compute_symbolic_derivatives_of_loss(s_loss)\n",
    "\n",
    "# set up optimization parameters\n",
    "\n",
    "alpha = 0.05        # learning rate\n",
    "N_iter = 100        # number of iterations\n",
    "\n",
    "K = 5               # perturbation samples per iteration\n",
    "perturbation_list = [-1., -0.75, -0.5, -0.25, 0.25, 0.5, 0.75, 1.]#, 2., 3., 4., 5., 6., 7., 8., 9., 10.]\n",
    "\n",
    "# output data structures\n",
    "loss_tape = []\n",
    "loss_tape_array = []\n",
    "parameter_tape = []\n",
    "gradient_tape = []\n",
    "optimizer_tape = []\n",
    "\n",
    "grad_history_ada = vec(zeros(length(pars_v)))\n",
    "momentum_adam = vec(zeros(length(pars_v)))\n",
    "velocity_adam = vec(zeros(length(pars_v)))\n",
    "non_pruned_parameters = vec(ones(length(pars_v))) # implement heuristic to prune parameters\n",
    "\n",
    "#push!(loss_tape, total_loss_eval(loss_args))\n",
    "push!(parameter_tape, pars_v)\n",
    "push!(gradient_tape, zeros(np))\n",
    "push!(optimizer_tape, zeros(np))\n",
    "\n",
    "# additional options\n",
    "use_pruning_heuristic = true\n",
    "clip_value = nothing\n",
    "use_gradient_normalization = false\n",
    "use_adagrad = true # overrides use_adam!\n",
    "use_adam = false\n",
    "use_random_perturbation = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\frac{\\frac{1}{2} w_2 \\left( \\left| - at_{t0\\_d_3} + at_{t0_3}\\right| + \\left| - at_{t1\\_d_3} + at_{t1_3}\\right| + \\left| - at_{t1\\_d_1} + at_{t1_1}\\right| + \\left| - at_{t1\\_d_2} + at_{t1_2}\\right| + \\left| - at_{t0\\_d_2} + at_{t0_2}\\right| + \\left| - at_{t0\\_d_1} + at_{t0_1}\\right| \\right)}{1 + \\frac{1}{2} \\left( \\left| - at_{t0\\_d_3} + at_{t0_3}\\right| + \\left| - at_{t1\\_d_3} + at_{t1_3}\\right| + \\left| - at_{t1\\_d_1} + at_{t1_1}\\right| + \\left| - at_{t1\\_d_2} + at_{t1_2}\\right| + \\left| - at_{t0\\_d_2} + at_{t0_2}\\right| + \\left| - at_{t0\\_d_1} + at_{t0_1}\\right| \\right)} + \\frac{\\left( p_{s} - \\mathrm{min}\\left( \\left| - o_{t0} + o_{t0pdt}\\right|, p_{s} \\right) \\right) w_1}{1 + p_{s} - \\mathrm{min}\\left( \\left| - o_{t0} + o_{t0pdt}\\right|, p_{s} \\right)} + \\frac{w_3 \\left( \\log\\left( 1 + k_{21} \\right) + \\log\\left( 1 + k_{65} \\right) + \\log\\left( 1 + k_{3} \\right) + \\log\\left( 1 + k_{4} \\right) + \\log\\left( 1 + k_{19} \\right) + \\log\\left( 1 + k_{5} \\right) + \\log\\left( 1 + k_{31} \\right) + \\log\\left( 1 + k_{14} \\right) + \\log\\left( 1 + k_{11} \\right) + \\log\\left( 1 + k_{16} \\right) + \\log\\left( 1 + k_{62} \\right) + \\log\\left( 1 + k_{78} \\right) + \\log\\left( 1 + k_{49} \\right) + \\log\\left( 1 + k_{76} \\right) + \\log\\left( 1 + k_{7} \\right) + \\log\\left( 1 + k_{67} \\right) + \\log\\left( 1 + k_{22} \\right) + \\log\\left( 1 + k_{35} \\right) + \\log\\left( 1 + k_{63} \\right) + \\log\\left( 1 + k_{52} \\right) + \\log\\left( 1 + k_{10} \\right) + \\log\\left( 1 + k_{73} \\right) + \\log\\left( 1 + k_{8} \\right) + \\log\\left( 1 + k_{80} \\right) + \\log\\left( 1 + k_{47} \\right) + \\log\\left( 1 + k_{30} \\right) + \\log\\left( 1 + k_{64} \\right) + \\log\\left( 1 + k_{51} \\right) + \\log\\left( 1 + k_{69} \\right) + \\log\\left( 1 + k_{13} \\right) + \\log\\left( 1 + k_{40} \\right) + \\log\\left( 1 + k_{34} \\right) + \\log\\left( 1 + k_{74} \\right) + \\log\\left( 1 + k_{61} \\right) + \\log\\left( 1 + k_{50} \\right) + \\log\\left( 1 + k_{70} \\right) + \\log\\left( 1 + k_{58} \\right) + \\log\\left( 1 + k_{71} \\right) + \\log\\left( 1 + k_{43} \\right) + \\log\\left( 1 + k_{57} \\right) + \\log\\left( 1 + k_{23} \\right) + \\log\\left( 1 + k_{25} \\right) + \\log\\left( 1 + k_{39} \\right) + \\log\\left( 1 + k_{17} \\right) + \\log\\left( 1 + k_{32} \\right) + \\log\\left( 1 + k_{75} \\right) + \\log\\left( 1 + k_{68} \\right) + \\log\\left( 1 + k_{59} \\right) + \\log\\left( 1 + k_{1} \\right) + \\log\\left( 1 + k_{41} \\right) + \\log\\left( 1 + k_{28} \\right) + \\log\\left( 1 + k_{54} \\right) + \\log\\left( 1 + k_{6} \\right) + \\log\\left( 1 + k_{9} \\right) + \\log\\left( 1 + k_{37} \\right) + \\log\\left( 1 + k_{55} \\right) + \\log\\left( 1 + k_{27} \\right) + \\log\\left( 1 + k_{2} \\right) + \\log\\left( 1 + k_{66} \\right) + \\log\\left( 1 + k_{36} \\right) + \\log\\left( 1 + k_{33} \\right) + \\log\\left( 1 + k_{18} \\right) + \\log\\left( 1 + k_{56} \\right) + \\log\\left( 1 + k_{60} \\right) + \\log\\left( 1 + k_{38} \\right) + \\log\\left( 1 + k_{77} \\right) + \\log\\left( 1 + k_{53} \\right) + \\log\\left( 1 + k_{72} \\right) + \\log\\left( 1 + k_{24} \\right) + \\log\\left( 1 + k_{15} \\right) + \\log\\left( 1 + k_{44} \\right) + \\log\\left( 1 + k_{42} \\right) + \\log\\left( 1 + k_{48} \\right) + \\log\\left( 1 + k_{26} \\right) + \\log\\left( 1 + k_{12} \\right) + \\log\\left( 1 + k_{20} \\right) + \\log\\left( 1 + k_{79} \\right) + \\log\\left( 1 + k_{46} \\right) + \\log\\left( 1 + k_{45} \\right) \\right)}{1 + \\log\\left( 1 + k_{21} \\right) + \\log\\left( 1 + k_{65} \\right) + \\log\\left( 1 + k_{3} \\right) + \\log\\left( 1 + k_{4} \\right) + \\log\\left( 1 + k_{19} \\right) + \\log\\left( 1 + k_{5} \\right) + \\log\\left( 1 + k_{31} \\right) + \\log\\left( 1 + k_{14} \\right) + \\log\\left( 1 + k_{11} \\right) + \\log\\left( 1 + k_{16} \\right) + \\log\\left( 1 + k_{62} \\right) + \\log\\left( 1 + k_{78} \\right) + \\log\\left( 1 + k_{49} \\right) + \\log\\left( 1 + k_{76} \\right) + \\log\\left( 1 + k_{7} \\right) + \\log\\left( 1 + k_{67} \\right) + \\log\\left( 1 + k_{22} \\right) + \\log\\left( 1 + k_{35} \\right) + \\log\\left( 1 + k_{63} \\right) + \\log\\left( 1 + k_{52} \\right) + \\log\\left( 1 + k_{10} \\right) + \\log\\left( 1 + k_{73} \\right) + \\log\\left( 1 + k_{8} \\right) + \\log\\left( 1 + k_{80} \\right) + \\log\\left( 1 + k_{47} \\right) + \\log\\left( 1 + k_{30} \\right) + \\log\\left( 1 + k_{64} \\right) + \\log\\left( 1 + k_{51} \\right) + \\log\\left( 1 + k_{69} \\right) + \\log\\left( 1 + k_{13} \\right) + \\log\\left( 1 + k_{40} \\right) + \\log\\left( 1 + k_{34} \\right) + \\log\\left( 1 + k_{74} \\right) + \\log\\left( 1 + k_{61} \\right) + \\log\\left( 1 + k_{50} \\right) + \\log\\left( 1 + k_{70} \\right) + \\log\\left( 1 + k_{58} \\right) + \\log\\left( 1 + k_{71} \\right) + \\log\\left( 1 + k_{43} \\right) + \\log\\left( 1 + k_{57} \\right) + \\log\\left( 1 + k_{23} \\right) + \\log\\left( 1 + k_{25} \\right) + \\log\\left( 1 + k_{39} \\right) + \\log\\left( 1 + k_{17} \\right) + \\log\\left( 1 + k_{32} \\right) + \\log\\left( 1 + k_{75} \\right) + \\log\\left( 1 + k_{68} \\right) + \\log\\left( 1 + k_{59} \\right) + \\log\\left( 1 + k_{1} \\right) + \\log\\left( 1 + k_{41} \\right) + \\log\\left( 1 + k_{28} \\right) + \\log\\left( 1 + k_{54} \\right) + \\log\\left( 1 + k_{6} \\right) + \\log\\left( 1 + k_{9} \\right) + \\log\\left( 1 + k_{37} \\right) + \\log\\left( 1 + k_{55} \\right) + \\log\\left( 1 + k_{27} \\right) + \\log\\left( 1 + k_{2} \\right) + \\log\\left( 1 + k_{66} \\right) + \\log\\left( 1 + k_{36} \\right) + \\log\\left( 1 + k_{33} \\right) + \\log\\left( 1 + k_{18} \\right) + \\log\\left( 1 + k_{56} \\right) + \\log\\left( 1 + k_{60} \\right) + \\log\\left( 1 + k_{38} \\right) + \\log\\left( 1 + k_{77} \\right) + \\log\\left( 1 + k_{53} \\right) + \\log\\left( 1 + k_{72} \\right) + \\log\\left( 1 + k_{24} \\right) + \\log\\left( 1 + k_{15} \\right) + \\log\\left( 1 + k_{44} \\right) + \\log\\left( 1 + k_{42} \\right) + \\log\\left( 1 + k_{48} \\right) + \\log\\left( 1 + k_{26} \\right) + \\log\\left( 1 + k_{12} \\right) + \\log\\left( 1 + k_{20} \\right) + \\log\\left( 1 + k_{79} \\right) + \\log\\left( 1 + k_{46} \\right) + \\log\\left( 1 + k_{45} \\right)} + \\frac{w_4 \\left( \\left| - o_{t0} + o_{t1}\\right| + \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)} \\right)}{1 + \\left| - o_{t0} + o_{t1}\\right| + \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)}}\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "((1//2)*w₂*(abs(-at_t0_d₃ + at_t0₃) + abs(-at_t1_d₃ + at_t1₃) + abs(-at_t1_d₁ + at_t1₁) + abs(-at_t1_d₂ + at_t1₂) + abs(-at_t0_d₂ + at_t0₂) + abs(-at_t0_d₁ + at_t0₁))) / (1.0 + (1//2)*(abs(-at_t0_d₃ + at_t0₃) + abs(-at_t1_d₃ + at_t1₃) + abs(-at_t1_d₁ + at_t1₁) + abs(-at_t1_d₂ + at_t1₂) + abs(-at_t0_d₂ + at_t0₂) + abs(-at_t0_d₁ + at_t0₁))) + ((p_s - min(abs(-o_t0 + o_t0pdt), p_s))*w₁) / (1.0 + p_s - min(abs(-o_t0 + o_t0pdt), p_s)) + (w₃*(log(1.0 + k_21) + log(1.0 + k_65) + log(1.0 + k_3) + log(1.0 + k_4) + log(1.0 + k_19) + log(1.0 + k_5) + log(1.0 + k_31) + log(1.0 + k_14) + log(1.0 + k_11) + log(1.0 + k_16) + log(1.0 + k_62) + log(1.0 + k_78) + log(1.0 + k_49) + log(1.0 + k_76) + log(1.0 + k_7) + log(1.0 + k_67) + log(1.0 + k_22) + log(1.0 + k_35) + log(1.0 + k_63) + log(1.0 + k_52) + log(1.0 + k_10) + log(1.0 + k_73) + log(1.0 + k_8) + log(1.0 + k_80) + log(1.0 + k_47) + log(1.0 + k_30) + log(1.0 + k_64) + log(1.0 + k_51) + log(1.0 + k_69) + log(1.0 + k_13) + log(1.0 + k_40) + log(1.0 + k_34) + log(1.0 + k_74) + log(1.0 + k_61) + log(1.0 + k_50) + log(1.0 + k_70) + log(1.0 + k_58) + log(1.0 + k_71) + log(1.0 + k_43) + log(1.0 + k_57) + log(1.0 + k_23) + log(1.0 + k_25) + log(1.0 + k_39) + log(1.0 + k_17) + log(1.0 + k_32) + log(1.0 + k_75) + log(1.0 + k_68) + log(1.0 + k_59) + log(1.0 + k_1) + log(1.0 + k_41) + log(1.0 + k_28) + log(1.0 + k_54) + log(1.0 + k_6) + log(1.0 + k_9) + log(1.0 + k_37) + log(1.0 + k_55) + log(1.0 + k_27) + log(1.0 + k_2) + log(1.0 + k_66) + log(1.0 + k_36) + log(1.0 + k_33) + log(1.0 + k_18) + log(1.0 + k_56) + log(1.0 + k_60) + log(1.0 + k_38) + log(1.0 + k_77) + log(1.0 + k_53) + log(1.0 + k_72) + log(1.0 + k_24) + log(1.0 + k_15) + log(1.0 + k_44) + log(1.0 + k_42) + log(1.0 + k_48) + log(1.0 + k_26) + log(1.0 + k_12) + log(1.0 + k_20) + log(1.0 + k_79) + log(1.0 + k_46) + log(1.0 + k_45))) / (1.0 + log(1.0 + k_21) + log(1.0 + k_65) + log(1.0 + k_3) + log(1.0 + k_4) + log(1.0 + k_19) + log(1.0 + k_5) + log(1.0 + k_31) + log(1.0 + k_14) + log(1.0 + k_11) + log(1.0 + k_16) + log(1.0 + k_62) + log(1.0 + k_78) + log(1.0 + k_49) + log(1.0 + k_76) + log(1.0 + k_7) + log(1.0 + k_67) + log(1.0 + k_22) + log(1.0 + k_35) + log(1.0 + k_63) + log(1.0 + k_52) + log(1.0 + k_10) + log(1.0 + k_73) + log(1.0 + k_8) + log(1.0 + k_80) + log(1.0 + k_47) + log(1.0 + k_30) + log(1.0 + k_64) + log(1.0 + k_51) + log(1.0 + k_69) + log(1.0 + k_13) + log(1.0 + k_40) + log(1.0 + k_34) + log(1.0 + k_74) + log(1.0 + k_61) + log(1.0 + k_50) + log(1.0 + k_70) + log(1.0 + k_58) + log(1.0 + k_71) + log(1.0 + k_43) + log(1.0 + k_57) + log(1.0 + k_23) + log(1.0 + k_25) + log(1.0 + k_39) + log(1.0 + k_17) + log(1.0 + k_32) + log(1.0 + k_75) + log(1.0 + k_68) + log(1.0 + k_59) + log(1.0 + k_1) + log(1.0 + k_41) + log(1.0 + k_28) + log(1.0 + k_54) + log(1.0 + k_6) + log(1.0 + k_9) + log(1.0 + k_37) + log(1.0 + k_55) + log(1.0 + k_27) + log(1.0 + k_2) + log(1.0 + k_66) + log(1.0 + k_36) + log(1.0 + k_33) + log(1.0 + k_18) + log(1.0 + k_56) + log(1.0 + k_60) + log(1.0 + k_38) + log(1.0 + k_77) + log(1.0 + k_53) + log(1.0 + k_72) + log(1.0 + k_24) + log(1.0 + k_15) + log(1.0 + k_44) + log(1.0 + k_42) + log(1.0 + k_48) + log(1.0 + k_26) + log(1.0 + k_12) + log(1.0 + k_20) + log(1.0 + k_79) + log(1.0 + k_46) + log(1.0 + k_45)) + (w₄*(abs(-o_t0 + o_t1) + (10(0.5 - min(o_t0, 0.5))) / (1.5 - min(o_t0, 0.5)))) / (1.0 + abs(-o_t0 + o_t1) + (10(0.5 - min(o_t0, 0.5))) / (1.5 - min(o_t0, 0.5)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\frac{w_1 \\mathrm{ifelse}\\left( \\left( \\left| - o_{t0} + o_{t0pdt}\\right| < p_{s} \\right), 1, 0 \\right) \\mathrm{ifelse}\\left( \\mathrm{signbit}\\left(  - o_{t0} + o_{t0pdt} \\right), -1, 1 \\right)}{1 + p_{s} - \\mathrm{min}\\left( \\left| - o_{t0} + o_{t0pdt}\\right|, p_{s} \\right)} + \\frac{w_4 \\left(  - \\mathrm{ifelse}\\left( \\mathrm{signbit}\\left(  - o_{t0} + o_{t1} \\right), -1, 1 \\right) + \\frac{ - 10 \\mathrm{ifelse}\\left( \\left( o_{t0} < 0.5 \\right), 1, 0 \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)} + \\mathrm{ifelse}\\left( \\left( o_{t0} < 0.5 \\right), 1, 0 \\right) \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{\\left( 1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)^{2}} \\right)}{1 + \\left| - o_{t0} + o_{t1}\\right| + \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)}} - \\mathrm{ifelse}\\left( \\left( \\left| - o_{t0} + o_{t0pdt}\\right| < p_{s} \\right), 1, 0 \\right) \\mathrm{ifelse}\\left( \\mathrm{signbit}\\left(  - o_{t0} + o_{t0pdt} \\right), -1, 1 \\right) \\frac{\\left( p_{s} - \\mathrm{min}\\left( \\left| - o_{t0} + o_{t0pdt}\\right|, p_{s} \\right) \\right) w_1}{\\left( 1 + p_{s} - \\mathrm{min}\\left( \\left| - o_{t0} + o_{t0pdt}\\right|, p_{s} \\right) \\right)^{2}} - \\left(  - \\mathrm{ifelse}\\left( \\mathrm{signbit}\\left(  - o_{t0} + o_{t1} \\right), -1, 1 \\right) + \\frac{ - 10 \\mathrm{ifelse}\\left( \\left( o_{t0} < 0.5 \\right), 1, 0 \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)} + \\mathrm{ifelse}\\left( \\left( o_{t0} < 0.5 \\right), 1, 0 \\right) \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{\\left( 1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)^{2}} \\right) \\frac{w_4 \\left( \\left| - o_{t0} + o_{t1}\\right| + \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)} \\right)}{\\left( 1 + \\left| - o_{t0} + o_{t1}\\right| + \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)} \\right)^{2}}\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "(w₁*ifelse(abs(-o_t0 + o_t0pdt) < p_s, 1, 0)*ifelse(signbit(-o_t0 + o_t0pdt), -1, 1)) / (1.0 + p_s - min(abs(-o_t0 + o_t0pdt), p_s)) + (w₄*(-ifelse(signbit(-o_t0 + o_t1), -1, 1) + (-10ifelse(o_t0 < 0.5, 1, 0)) / (1.5 - min(o_t0, 0.5)) + ifelse(o_t0 < 0.5, 1, 0)*((10(0.5 - min(o_t0, 0.5))) / ((1.5 - min(o_t0, 0.5))^2)))) / (1.0 + abs(-o_t0 + o_t1) + (10(0.5 - min(o_t0, 0.5))) / (1.5 - min(o_t0, 0.5))) - ifelse(abs(-o_t0 + o_t0pdt) < p_s, 1, 0)*ifelse(signbit(-o_t0 + o_t0pdt), -1, 1)*(((p_s - min(abs(-o_t0 + o_t0pdt), p_s))*w₁) / ((1.0 + p_s - min(abs(-o_t0 + o_t0pdt), p_s))^2)) - (-ifelse(signbit(-o_t0 + o_t1), -1, 1) + (-10ifelse(o_t0 < 0.5, 1, 0)) / (1.5 - min(o_t0, 0.5)) + ifelse(o_t0 < 0.5, 1, 0)*((10(0.5 - min(o_t0, 0.5))) / ((1.5 - min(o_t0, 0.5))^2)))*((w₄*(abs(-o_t0 + o_t1) + (10(0.5 - min(o_t0, 0.5))) / (1.5 - min(o_t0, 0.5)))) / ((1.0 + abs(-o_t0 + o_t1) + (10(0.5 - min(o_t0, 0.5))) / (1.5 - min(o_t0, 0.5)))^2))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Symbolics.derivative(s_loss, o_t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\frac{ - w_1 \\mathrm{ifelse}\\left( \\left( \\left| - o_{t0} + o_{t0pdt}\\right| < p_{s} \\right), 1, 0 \\right) \\mathrm{ifelse}\\left( \\mathrm{signbit}\\left(  - o_{t0} + o_{t0pdt} \\right), -1, 1 \\right)}{1 + p_{s} - \\mathrm{min}\\left( \\left| - o_{t0} + o_{t0pdt}\\right|, p_{s} \\right)} + \\mathrm{ifelse}\\left( \\left( \\left| - o_{t0} + o_{t0pdt}\\right| < p_{s} \\right), 1, 0 \\right) \\mathrm{ifelse}\\left( \\mathrm{signbit}\\left(  - o_{t0} + o_{t0pdt} \\right), -1, 1 \\right) \\frac{\\left( p_{s} - \\mathrm{min}\\left( \\left| - o_{t0} + o_{t0pdt}\\right|, p_{s} \\right) \\right) w_1}{\\left( 1 + p_{s} - \\mathrm{min}\\left( \\left| - o_{t0} + o_{t0pdt}\\right|, p_{s} \\right) \\right)^{2}}\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "(-w₁*ifelse(abs(-o_t0 + o_t0pdt) < p_s, 1, 0)*ifelse(signbit(-o_t0 + o_t0pdt), -1, 1)) / (1.0 + p_s - min(abs(-o_t0 + o_t0pdt), p_s)) + ifelse(abs(-o_t0 + o_t0pdt) < p_s, 1, 0)*ifelse(signbit(-o_t0 + o_t0pdt), -1, 1)*(((p_s - min(abs(-o_t0 + o_t0pdt), p_s))*w₁) / ((1.0 + p_s - min(abs(-o_t0 + o_t0pdt), p_s))^2))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Symbolics.derivative(s_loss, o_t0pdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\frac{w_4 \\mathrm{ifelse}\\left( \\mathrm{signbit}\\left(  - o_{t0} + o_{t1} \\right), -1, 1 \\right)}{1 + \\left| - o_{t0} + o_{t1}\\right| + \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)}} - \\frac{w_4 \\left( \\left| - o_{t0} + o_{t1}\\right| + \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)} \\right)}{\\left( 1 + \\left| - o_{t0} + o_{t1}\\right| + \\frac{10 \\left( 0.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right) \\right)}{1.5 - \\mathrm{min}\\left( o_{t0}, 0.5 \\right)} \\right)^{2}} \\mathrm{ifelse}\\left( \\mathrm{signbit}\\left(  - o_{t0} + o_{t1} \\right), -1, 1 \\right)\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "(w₄*ifelse(signbit(-o_t0 + o_t1), -1, 1)) / (1.0 + abs(-o_t0 + o_t1) + (10(0.5 - min(o_t0, 0.5))) / (1.5 - min(o_t0, 0.5))) - ((w₄*(abs(-o_t0 + o_t1) + (10(0.5 - min(o_t0, 0.5))) / (1.5 - min(o_t0, 0.5)))) / ((1.0 + abs(-o_t0 + o_t1) + (10(0.5 - min(o_t0, 0.5))) / (1.5 - min(o_t0, 0.5)))^2))*ifelse(signbit(-o_t0 + o_t1), -1, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Symbolics.derivative(s_loss, o_t1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiling @(100, 5) ~ 18s \n",
    "for i in 1:N_iter\n",
    "    gradient = zeros(np) # zero the gradient\n",
    "    loss_tape = push!(loss_tape, 0.)\n",
    "    loss_tape_array = push!(loss_tape_array, zeros(n_losses))\n",
    "    if use_random_perturbation\n",
    "        for _ in 1:K\n",
    "            # profiling @(100, 5) ~ 13.5s \n",
    "            sol = run_extended(ext_ode, pars_v, pars_l, input, perturbation, t0, t1)      # change to be more flexible in the perturbation events\n",
    "            # profiling @(100, 5) ~ 0s \n",
    "            loss_args = update_args(sol, target, t0, t1, pars_l, loss_args, p, d, f_ss)   # prepare the input for the next step\n",
    "            # profiling @(100, 5) ~ 3s\n",
    "            loss = total_loss_eval(loss_args)\n",
    "            loss_tape[end] += loss.total.val                        # record the loss\n",
    "            loss_tape_array[end] += loss.array\n",
    "            # symbolically \"backpropagate\"\n",
    "            # profiling @(100, 5) ~ 3s\n",
    "            jacobian = jacobian_pars(ext_ode, loss_args, loss_derivatives, sol, N, t0, t1, pars_v, f_ss, d, [[Symbol(\"x_$(i)\") for i in 1:N]..., Symbol(\"U\")])\n",
    "            # profiling @(100, 5) ~ 1s\n",
    "            gradient += vec([v.val for v in jacobian.sensitivity])  # check efficiency with symbolic operations (maybe we have to use \"real\" types directly)\n",
    "        end\n",
    "    else\n",
    "        solutions = run_extended_with_fixed_perturbations(ext_ode, pars_l, input, perturbation_list, t0, t1)\n",
    "        for sol in solutions\n",
    "            loss_args = update_args(sol, target, t0, t1, pars_l, loss_args, p, d, f_ss)   # prepare the input for the next step\n",
    "            loss = total_loss_eval(loss_args)\n",
    "            loss_tape[end] = loss_tape[end] + loss.total.val              # record the loss\n",
    "            loss_tape_array[end] = loss_tape_array[end] + loss.array\n",
    "            # symbolically \"backpropagate\"\n",
    "            jacobian = jacobian_pars(ext_ode, loss_args, loss_derivatives, sol, N, t0, t1, pars_v, f_ss, d, [[Symbol(\"x_$(i)\") for i in 1:N]..., Symbol(\"U\")])\n",
    "            gradient += vec([v.val for v in jacobian.sensitivity])  # check efficiency with symbolic operations (maybe we have to use \"real\" types directly)\n",
    "        end\n",
    "    end\n",
    "    if use_random_perturbation\n",
    "        loss_tape[end] /= K # average the recorded loss\n",
    "        loss_tape_array[end] ./= K\n",
    "        gradient /= K       # average the gradient\n",
    "    else\n",
    "        loss_tape[end] /= length(perturbation_list) # average the recorded loss\n",
    "        loss_tape_array[end] ./= length(perturbation_list)\n",
    "        gradient /= length(perturbation_list)       # average the gradient\n",
    "    end\n",
    "\n",
    "    if use_pruning_heuristic \n",
    "        gradient = gradient .* non_pruned_parameters\n",
    "    end\n",
    "\n",
    "    if clip_value != nothing\n",
    "        gradient = max.(min.(gradient, clip_value), -clip_value)\n",
    "    end\n",
    "    if use_gradient_normalization\n",
    "        m = maximum(abs.(gradient))\n",
    "        if m > 1.\n",
    "            gradient /= m\n",
    "        end\n",
    "    end\n",
    "    if use_adagrad\n",
    "        lr = adagrad_update_get_coefficient(pars_v, gradient, grad_history_ada, alpha)\n",
    "        push!(optimizer_tape, lr)\n",
    "    elseif use_adam\n",
    "        lr = ADAM_update_get_coefficient(pars_v, gradient, momentum_adam, velocity_adam, alpha, i, 0.9, 0.9, 1e-8)\n",
    "        push!(optimizer_tape, lr)\n",
    "    else\n",
    "        lr = alpha\n",
    "    end\n",
    "    \n",
    "    # update the parameters (avoid negative values) \n",
    "    \n",
    "    if use_pruning_heuristic\n",
    "        pars_v = max.(0., pars_v - (lr .* gradient)).*non_pruned_parameters\n",
    "        non_pruned_parameters = (pars_v .> 0.0001)\n",
    "    else\n",
    "        pars_v = max.(0., pars_v - (lr .* gradient))\n",
    "    end\n",
    "    # update dictionary like parameters\n",
    "    pars_l = assemble_opt_parameters_and_varables(pars_v, N) \n",
    "    \n",
    "    push!(parameter_tape, pars_v)\n",
    "    push!(gradient_tape, gradient)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Loess\n",
    "loss_names = [\"sensitivity\", \"steady-state\", \"L1\", \"adaptation\"]\n",
    "plot(1:length(loss_tape), loss_tape, label=\"loss\", xlabel=\"iteration\", ylabel=\"loss\", title=\"Loss vs iteration\", lw=2, legend=:topright)\n",
    "# smooth interpolation of the loss\n",
    "model = loess(1:length(loss_tape), convert(Vector{Float64}, loss_tape), span=0.5)\n",
    "predictions = predict(model, 1:length(loss_tape))\n",
    "plot!(1:length(loss_tape), predictions, label=\"smoothed loss\", lw=2, line=:dash)\n",
    "for i in 1:n_losses\n",
    "    #if sum([x[i].val for x in loss_tape_array]) > 0.\n",
    "    plot!(1:length(loss_tape), [x[i].val for x in loss_tape_array], lw=1, line=:dot, label=loss_names[i])\n",
    "    #end\n",
    "end\n",
    "plot!()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 1:n_losses\n",
    "    if i == 3\n",
    "        continue\n",
    "    end\n",
    "    if i == 1\n",
    "        plot(1:length(loss_tape), [x[i].val for x in loss_tape_array], lw=1, line=:dot, label=loss_names[i])\n",
    "    else\n",
    "        plot!(1:length(loss_tape), [x[i].val for x in loss_tape_array], lw=1, line=:dot, label=loss_names[i])\n",
    "    end\n",
    "end\n",
    "plot!()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Response on best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb = 2\n",
    "#opt_index = argmin(loss_tape)\n",
    "#opt_index = argmin(predictions)\n",
    "opt_index = length(loss_tape) \n",
    "\n",
    "opt_pars_v = parameter_tape[opt_index]\n",
    "opt_pars_l = assemble_opt_parameters_and_varables(opt_pars_v, N)\n",
    "\n",
    "sol = run_extended_with_fixed_perturbations(ext_ode, opt_pars_l, input, [ perturb ], t0, t1)[1]\n",
    "println(\"Optimal index: \", opt_index)\n",
    "println(\"Adaptation error: \", abs(sol(t0)[3] - sol(t1)[3]))\n",
    "println(\"sensitivity: \", abs(sol(t0)[3] - sol(t0+d)[3]), \" and  loss : \", abs(abs(sol(t0)[3] - sol(t0+d)[3]) - p))\n",
    "plot(sol.t, vec2mat(sol.u)[:,1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom on reaction 3\n",
    "plot(sol.t, vec2mat(sol.u)[:,3], label=\"Output\", xlabel=\"time\", ylabel=\"concentration\", title=\"Optimal solution\", lw=2)\n",
    "xlims!(t0-1., t0+2)\n",
    "ylims!(sol(t0-1)[3]-sol(t0-1)[3]*0.3, sol(t0+2)[3]+sol(t0+2)[3]*0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the response on the 3rd species for the three options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_index_options = [argmin(loss_tape), argmin(predictions), length(loss_tape)]\n",
    "opt_index_options_labels = [\"min loss\", \"min smoothed loss\", \"last iteration\"]\n",
    "opt_index_options_colors = [:red, :green, :blue]\n",
    "for i in 1:length(opt_index_options)\n",
    "    opt_index = opt_index_options[i]\n",
    "    opt_pars_v = parameter_tape[opt_index]\n",
    "    opt_pars_l = assemble_opt_parameters_and_varables(opt_pars_v, N)\n",
    "    sol = run_extended_with_fixed_perturbations(ext_ode, opt_pars_l, input, [ perturb ], t0, t1)[1]\n",
    "    if i == 1\n",
    "        plot(sol.t, vec2mat(sol.u)[:,3], label=opt_index_options_labels[i], xlabel=\"time\", ylabel=\"state\", title=\"Optimal solution\", lw=1, legend=:bottomleft, color=opt_index_options_colors[i])\n",
    "        plot!(sol.t, vec2mat(sol.u)[:,4], label=\"input (U)\", lw=1, legend=:bottomleft)\n",
    "    else\n",
    "        plot!(sol.t, vec2mat(sol.u)[:,3], label=opt_index_options_labels[i], lw=1, legend=:bottomleft, color=opt_index_options_colors[i])\n",
    "    end\n",
    "end\n",
    "plot!()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(1:length(gradient_tape), vec2mat(gradient_tape), legend=false, title=\"Gradient\", xlabel=\"Iteration\", ylabel=\"Gradient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(1:length(optimizer_tape), vec2mat(optimizer_tape), label=\"Optimizer correction term\", xlabel=\"Iteration\", ylabel=\"Correction term\", title=\"Optimizer correction term\", lw=2, legend=false, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2mat(gradient_tape)[end,gradient_tape[end].>0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(1:length(parameter_tape), vec2mat(parameter_tape), legend=false, title=\"Parameters\", xlabel=\"Iteration\", ylabel=\"Parameter value\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prameter histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_index_options = [argmin(loss_tape), argmin(predictions), length(loss_tape)]\n",
    "opt_index_options_labels = [\"min loss\", \"min smoothed loss\", \"last iteration\"]\n",
    "opt_index_options_colors = [:red, :green, :blue]\n",
    "\n",
    "hists = []\n",
    "for i in 1:length(opt_index_options)\n",
    "    opt_index = opt_index_options[i]\n",
    "    opt_pars_v = parameter_tape[opt_index]\n",
    "    opt_pars_l = assemble_opt_parameters_and_varables(opt_pars_v, N)\n",
    "    h = histogram(opt_pars_v, label=opt_index_options_labels[i], xlabel=\"Parameter value\", ylabel=\"Frequency\", title=opt_index_options_labels[i], lw=2, legend=false, color=opt_index_options_colors[i], bins=20)\n",
    "    push!(hists, h)\n",
    "end\n",
    "plot(hists..., layout=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2mat(gradient_tape)[2,gradient_tape[2].<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_tape[2].>0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate adaptation type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Symbolics\n",
    "using LinearAlgebra\n",
    "function joint_jacobian(i, j, jac, initial_conditions)\n",
    "    A_ij = substitute(jac[i, j], unsym_dict(initial_conditions))\n",
    "    return A_ij\n",
    "end\n",
    "\n",
    "opt_index = argmin(loss_tape)\n",
    "# opt_index = argmin(predictions)\n",
    "# opt_index = length(loss_tape)\n",
    "\n",
    "opt_pars_v = parameter_tape[opt_index]\n",
    "opt_pars_l = assemble_opt_parameters_and_varables(opt_pars_v, N)\n",
    "\n",
    "jac = Symbolics.substitute(calculate_jacobian(ode_crn), unsym_dict(opt_pars_l.p))\n",
    "\n",
    "perturb = 1.\n",
    "steady_state_after_perturbation = run_extended_with_fixed_perturbations(ext_ode, opt_pars_l, input, [ perturb ], t0, t1)[1](t1)[1:3]\n",
    "steady_state_after_perturbation = [\n",
    "    :x_1 => steady_state_after_perturbation[1],\n",
    "    :x_2 => steady_state_after_perturbation[2],\n",
    "    :x_3 => steady_state_after_perturbation[3]\n",
    "]\n",
    "\n",
    "A_21 = joint_jacobian(2, 1, jac, steady_state_after_perturbation)\n",
    "A_32 = joint_jacobian(3, 2, jac, steady_state_after_perturbation)\n",
    "A_22 = joint_jacobian(2, 2, jac, steady_state_after_perturbation)\n",
    "A_31 = joint_jacobian(3, 1, jac, steady_state_after_perturbation)\n",
    "\n",
    "println(\"A_21 = \", A_21)\n",
    "println(\"A_32 = \", A_32)\n",
    "println(\"A_22 = \", A_22)\n",
    "println(\"A_31 = \", A_31)\n",
    "println(\"A_22*A_31 = \", A_22*A_31)\n",
    "println(\"A_21*A_32 = \", A_21*A_32)\n",
    "println(\"A_22*A_31 - A_21*A_32 = \", A_22*A_31 - A_21*A_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symbolics.substitute(jac, unsym_dict(steady_state_after_perturbation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steady_state_after_perturbation = run_extended_with_fixed_perturbations(ext_ode, opt_pars_l, input, [ perturb ], t0, t1)[1](t1)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO to be fixed\n",
    "compute_homeostatic_coefficient(crn, calculate_jacobian(ode_crn), [1 for i in 1:np])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check surviving reactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_index = length(loss_tape)\n",
    "ranks = reverse(sortperm(abs.(parameter_tape[opt_index])))\n",
    "\n",
    "for i in ranks\n",
    "    if i != 1\n",
    "        println(parameter_tape[opt_index][i], \" : \", reactions(crn)[2:end][i])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensitivity(ode_crn, pars_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_v = [0. for i in 1:np]\n",
    "pars_l = assemble_opt_parameters_and_varables(pars_v, N)\n",
    "sol = run_extended(ext_ode, pars_v, pars_l, input, perturbation, t0, t1)\n",
    "sm = sensitivity_from_ode(ode_crn, sol, t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm[1, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sol.t, vec2mat(sol.u)[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sol.t, vec2mat(sol.u)[:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10.0*substitute(compute_symbolic_derivatives_of_loss(s_loss)[o_t0], unsym_dict(Dict(\n",
    "    :o_t0 => sol(t0)[3],\n",
    "    :o_t0pdt => sol(t0+d)[3], \n",
    "    :o_t1 => sol(t1)[3],\n",
    "    :p_s => 0.05\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10.0*substitute(compute_symbolic_derivatives_of_loss(s_loss)[o_t1], unsym_dict(Dict(\n",
    "    :o_t0 => sol(t0)[3],\n",
    "    :o_t0pdt => sol(t0+d)[3], \n",
    "    :o_t1 => sol(t1)[3],\n",
    "    :p_s => 0.05\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10.0*substitute(compute_symbolic_derivatives_of_loss(s_loss)[o_t0pdt], unsym_dict(Dict(\n",
    "    :o_t0 => sol(t0)[3],\n",
    "    :o_t0pdt => sol(t0+d)[3], \n",
    "    :o_t1 => sol(t1)[3],\n",
    "    :p_s => 0.05\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findall((x) -> isequal(x,:k_54), [ i for i in keys(pars_l.p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_tape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_pars(ode_crn, loss_args, loss_derivatives, sol, 3, 10., 20., pars_v, 0.5, 0.1, [[Symbol(\"x_$(i)\") for i in 1:3]..., Symbol(\"U\")]).sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity(ode_crn, pars_v)[:, 54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_pars(ode_crn, loss_args, loss_derivatives, sol, 3, 10., 20., pars_v, 0.5, 0.1, [[Symbol(\"x_$(i)\") for i in 1:3]..., Symbol(\"U\")]).sensitivity[54]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
